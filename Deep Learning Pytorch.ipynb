{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d40529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8ee240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn  # for heatmaps\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e2fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('imagenet_subset_gray.pkl','rb')\n",
    "\n",
    "X_train = pickle.load(file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f76626",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('imagenet_subset.pkl','rb')\n",
    "\n",
    "y_train = pickle.load(file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d13fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('imagenet_testset_gray.pkl','rb')\n",
    "\n",
    "X_test = pickle.load(file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "257ad983",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('imagenet_testset.pkl','rb')\n",
    "\n",
    "y_test = pickle.load(file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48e6a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('imagenet_valset_gray.pkl','rb')\n",
    "\n",
    "X_val = pickle.load(file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "930af136",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('imagenet_valset.pkl','rb')\n",
    "\n",
    "y_val = pickle.load(file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "342e8d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/b6gng55n3rj1cq8m2v30vqy00000gn/T/ipykernel_24313/228119852.py:1: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  X_train_tensor = torch.tensor(X_train,dtype=torch.uint8) # transform to torch tensor\n",
      "/var/folders/ff/b6gng55n3rj1cq8m2v30vqy00000gn/T/ipykernel_24313/228119852.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:233.)\n",
      "  X_train_tensor = torch.tensor(X_train,dtype=torch.uint8) # transform to torch tensor\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(X_train,dtype=torch.uint8) # transform to torch tensor\n",
    "y_train_tensor = torch.tensor(y_train,dtype=torch.uint8)\n",
    "\n",
    "train = TensorDataset(X_train_tensor,y_train_tensor) # create your datset\n",
    "train_loader = DataLoader(train,batch_size=100, shuffle=False) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb28d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7a40415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/b6gng55n3rj1cq8m2v30vqy00000gn/T/ipykernel_24313/978350706.py:1: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  X_test_tensor = torch.tensor(X_test,dtype=torch.uint8) # transform to torch tensor\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.tensor(X_test,dtype=torch.uint8) # transform to torch tensor\n",
    "y_test_tensor = torch.tensor(y_test,dtype=torch.uint8)\n",
    "\n",
    "test = TensorDataset(X_test_tensor,y_test_tensor) # create your datset\n",
    "test_loader = DataLoader(test,batch_size=100, shuffle=False) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64502708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/b6gng55n3rj1cq8m2v30vqy00000gn/T/ipykernel_24313/107551794.py:1: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  X_val_tensor = torch.tensor(X_val,dtype=torch.uint8) # transform to torch tensor\n"
     ]
    }
   ],
   "source": [
    "X_val_tensor = torch.tensor(X_val,dtype=torch.uint8) # transform to torch tensor\n",
    "y_val_tensor = torch.tensor(y_val,dtype=torch.uint8)\n",
    "\n",
    "val = TensorDataset(X_val_tensor,y_val_tensor) # create your datset\n",
    "val_loader = DataLoader(val,batch_size=100, shuffle=False) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "116caaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128, 128, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for a,b in train_loader:\n",
    "    break\n",
    "    \n",
    "a = a.view(-1,1,128,128)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "044ca54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "\n",
    "\n",
    "class Trim(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :128, :128]\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential( #784\n",
    "                nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(3, 3), padding=1),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(inplace=True),\n",
    "                nn.Conv2d(32, 64, stride=(2, 2), kernel_size=(3, 3), padding=1),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(inplace=True),\n",
    "\n",
    "                nn.Conv2d(64, 128, stride=(2, 2), kernel_size=(3, 3), padding=1),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(inplace=True),\n",
    "\n",
    "                nn.Conv2d(128, 256, stride=(2, 2), kernel_size=(3, 3), padding=1),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(inplace=True),\n",
    "\n",
    "\n",
    "                nn.Conv2d(256, 512, stride=(2, 2), kernel_size=(3, 3), padding=1),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(inplace=True),\n",
    "            \n",
    "                nn.Conv2d(512, 64, stride=(1, 1), kernel_size=(3, 3), padding=1),\n",
    "                \n",
    "                nn.Flatten(),\n",
    "                nn.Linear(4096, 2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "                torch.nn.Linear(2, 4096),\n",
    "                Reshape(-1, 64, 8, 8),\n",
    "                nn.ConvTranspose2d(64, 64, stride=(1, 1), kernel_size=(3, 3), padding=1),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(inplace=True),\n",
    "\n",
    "                nn.ConvTranspose2d(64, 64, stride=(2, 2), kernel_size=(3, 3), padding=1),                \n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(inplace=True),\n",
    "            \n",
    "                nn.ConvTranspose2d(64, 32, stride=(2, 2), kernel_size=(3, 3), padding=0),                \n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(inplace=True),\n",
    "            \n",
    "                nn.ConvTranspose2d(32, 32, stride=(1, 1), kernel_size=(3, 3), padding=0), \n",
    "                nn.ConvTranspose2d(32, 16, stride=(2, 2), kernel_size=(3, 3), padding=1),                \n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(inplace=True),\n",
    "                nn.ConvTranspose2d(16, 3, stride=(2, 2), kernel_size=(3, 3), padding=1),                \n",
    "                Trim(),  # 1x29x29 -> 1x28x28\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdcd3a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.5, inplace=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): Dropout(p=0.5, inplace=True)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): Dropout(p=0.5, inplace=True)\n",
       "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (10): LeakyReLU(negative_slope=0.01)\n",
       "    (11): Dropout(p=0.5, inplace=True)\n",
       "    (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (13): LeakyReLU(negative_slope=0.01)\n",
       "    (14): Dropout(p=0.5, inplace=True)\n",
       "    (15): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): Flatten(start_dim=1, end_dim=-1)\n",
       "    (17): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=4096, bias=True)\n",
       "    (1): Reshape()\n",
       "    (2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Dropout(p=0.5, inplace=True)\n",
       "    (5): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (6): LeakyReLU(negative_slope=0.01)\n",
       "    (7): Dropout(p=0.5, inplace=True)\n",
       "    (8): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (9): LeakyReLU(negative_slope=0.01)\n",
       "    (10): Dropout(p=0.5, inplace=True)\n",
       "    (11): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (12): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (13): LeakyReLU(negative_slope=0.01)\n",
       "    (14): Dropout(p=0.5, inplace=True)\n",
       "    (15): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (16): Trim()\n",
       "    (17): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(101)\n",
    "model = AutoEncoder()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e2376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "938cf57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(c,i,actual):\n",
    "    print(c)\n",
    "    plt.imshow(c.reshape(128,128,3))\n",
    "    plt.savefig(f'{i} c.png')\n",
    "    \n",
    "    \n",
    "    plt.imshow(actual.reshape(128,128,3))\n",
    "    plt.savefig(f'Actual {i} actual.png')\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efa9b489",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2cf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:03,  3.63s/it]\u001b[A\n",
      "2it [00:07,  3.54s/it]\u001b[A\n",
      "3it [00:10,  3.46s/it]\u001b[A\n",
      "4it [00:15,  4.01s/it]\u001b[A\n",
      "5it [00:18,  3.72s/it]\u001b[A\n",
      "6it [00:22,  3.64s/it]\u001b[A\n",
      "7it [00:25,  3.54s/it]\u001b[A\n",
      "8it [00:28,  3.45s/it]\u001b[A\n",
      "9it [00:31,  3.40s/it]\u001b[A\n",
      "10it [00:35,  3.32s/it]\u001b[A\n",
      "11it [00:38,  3.37s/it]\u001b[A\n",
      "12it [00:41,  3.33s/it]\u001b[A\n",
      "13it [00:45,  3.35s/it]\u001b[A\n",
      "14it [00:48,  3.28s/it]\u001b[A\n",
      "15it [00:51,  3.30s/it]\u001b[A\n",
      "16it [00:54,  3.24s/it]\u001b[A\n",
      "17it [00:57,  3.15s/it]\u001b[A\n",
      "18it [01:01,  3.25s/it]\u001b[A\n",
      "19it [01:04,  3.23s/it]\u001b[A\n",
      "20it [01:07,  3.18s/it]\u001b[A\n",
      "21it [01:10,  3.26s/it]\u001b[A\n",
      "22it [01:14,  3.30s/it]\u001b[A\n",
      "23it [01:17,  3.23s/it]\u001b[A\n",
      "24it [01:20,  3.24s/it]\u001b[A\n",
      "25it [01:24,  3.40s/it]\u001b[A\n",
      "26it [01:29,  3.86s/it]\u001b[A\n",
      "27it [01:33,  4.05s/it]\u001b[A\n",
      "28it [01:36,  3.81s/it]\u001b[A\n",
      "29it [01:40,  3.65s/it]\u001b[A\n",
      "30it [01:43,  3.58s/it]\u001b[A\n",
      "31it [01:46,  3.49s/it]\u001b[A\n",
      "32it [01:50,  3.41s/it]\u001b[A\n",
      "33it [01:53,  3.36s/it]\u001b[A\n",
      "34it [01:57,  3.65s/it]\u001b[A\n",
      "35it [02:01,  3.69s/it]\u001b[A\n",
      "36it [02:06,  3.95s/it]\u001b[A\n",
      "37it [02:09,  3.82s/it]\u001b[A\n",
      "38it [02:13,  3.71s/it]\u001b[A\n",
      "39it [02:16,  3.55s/it]\u001b[A\n",
      "40it [02:19,  3.38s/it]\u001b[A\n",
      "41it [02:22,  3.38s/it]\u001b[A\n",
      "42it [02:25,  3.33s/it]\u001b[A\n",
      "43it [02:29,  3.28s/it]\u001b[A\n",
      "44it [02:32,  3.22s/it]\u001b[A\n",
      "45it [02:35,  3.22s/it]\u001b[A\n",
      "46it [02:38,  3.17s/it]\u001b[A\n",
      "47it [02:41,  3.19s/it]\u001b[A\n",
      "48it [02:44,  3.16s/it]\u001b[A\n",
      "49it [02:47,  3.12s/it]\u001b[A\n",
      "50it [02:51,  3.20s/it]\u001b[A\n",
      "51it [02:54,  3.20s/it]\u001b[A\n",
      "52it [02:58,  3.43s/it]\u001b[A\n",
      "53it [03:01,  3.50s/it]\u001b[A\n",
      "54it [03:05,  3.40s/it]\u001b[A\n",
      "55it [03:08,  3.31s/it]\u001b[A\n",
      "56it [03:11,  3.31s/it]\u001b[A\n",
      "57it [03:14,  3.26s/it]\u001b[A\n",
      "58it [03:17,  3.18s/it]\u001b[A\n",
      "59it [03:21,  3.24s/it]\u001b[A\n",
      "60it [03:24,  3.22s/it]\u001b[A\n",
      "61it [03:27,  3.38s/it]\u001b[A\n",
      "62it [03:31,  3.51s/it]\u001b[A\n",
      "63it [03:34,  3.42s/it]\u001b[A\n",
      "64it [03:38,  3.38s/it]\u001b[A\n",
      "65it [03:41,  3.47s/it]\u001b[A\n",
      "66it [03:45,  3.38s/it]\u001b[A\n",
      "67it [03:48,  3.30s/it]\u001b[A\n",
      "68it [03:51,  3.29s/it]\u001b[A\n",
      "69it [03:54,  3.26s/it]\u001b[A\n",
      "70it [03:57,  3.25s/it]\u001b[A\n",
      "71it [04:01,  3.24s/it]\u001b[A\n",
      "72it [04:04,  3.16s/it]\u001b[A\n",
      "73it [04:07,  3.14s/it]\u001b[A\n",
      "74it [04:10,  3.30s/it]\u001b[A\n",
      "75it [04:13,  3.23s/it]\u001b[A\n",
      "76it [04:17,  3.21s/it]\u001b[A\n",
      "77it [04:20,  3.21s/it]\u001b[A\n",
      "78it [04:23,  3.21s/it]\u001b[A\n",
      "79it [04:26,  3.21s/it]\u001b[A\n",
      "80it [04:29,  3.18s/it]\u001b[A\n",
      "81it [04:33,  3.18s/it]\u001b[A\n",
      "82it [04:36,  3.21s/it]\u001b[A\n",
      "83it [04:40,  3.49s/it]\u001b[A\n",
      "84it [04:43,  3.34s/it]\u001b[A\n",
      "85it [04:46,  3.32s/it]\u001b[A\n",
      "86it [04:49,  3.26s/it]\u001b[A\n",
      "87it [04:53,  3.25s/it]\u001b[A\n",
      "88it [04:56,  3.23s/it]\u001b[A\n",
      "89it [04:59,  3.18s/it]\u001b[A\n",
      "90it [05:02,  3.22s/it]\u001b[A\n",
      "91it [05:05,  3.23s/it]\u001b[A\n",
      "92it [05:09,  3.27s/it]\u001b[A\n",
      "93it [05:12,  3.22s/it]\u001b[A\n",
      "94it [05:16,  3.37s/it]\u001b[A\n",
      "95it [05:19,  3.44s/it]\u001b[A\n",
      "96it [05:27,  4.87s/it]\u001b[A\n",
      "97it [05:32,  4.73s/it]\u001b[A\n",
      "98it [05:36,  4.54s/it]\u001b[A\n",
      "99it [05:38,  3.41s/it]\u001b[A\n",
      "  3%|█▎                                       | 1/30 [05:38<2:43:25, 338.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "tensor([[[[0.4654, 0.4687, 0.4662,  ..., 0.4721, 0.4644, 0.4775],\n",
      "          [0.4723, 0.4755, 0.4670,  ..., 0.4652, 0.4735, 0.4668],\n",
      "          [0.4643, 0.4655, 0.4645,  ..., 0.4626, 0.4639, 0.4686],\n",
      "          ...,\n",
      "          [0.4768, 0.4681, 0.4696,  ..., 0.4667, 0.4592, 0.4678],\n",
      "          [0.4689, 0.4690, 0.4581,  ..., 0.4718, 0.4590, 0.4621],\n",
      "          [0.4722, 0.4632, 0.4681,  ..., 0.4659, 0.4647, 0.4695]],\n",
      "\n",
      "         [[0.4383, 0.4462, 0.4404,  ..., 0.4336, 0.4364, 0.4435],\n",
      "          [0.4405, 0.4475, 0.4436,  ..., 0.4375, 0.4364, 0.4378],\n",
      "          [0.4417, 0.4443, 0.4415,  ..., 0.4429, 0.4403, 0.4401],\n",
      "          ...,\n",
      "          [0.4329, 0.4397, 0.4388,  ..., 0.4442, 0.4362, 0.4388],\n",
      "          [0.4404, 0.4402, 0.4358,  ..., 0.4407, 0.4366, 0.4388],\n",
      "          [0.4336, 0.4402, 0.4355,  ..., 0.4463, 0.4330, 0.4381]],\n",
      "\n",
      "         [[0.4255, 0.4325, 0.4232,  ..., 0.4286, 0.4245, 0.4262],\n",
      "          [0.4303, 0.4378, 0.4338,  ..., 0.4333, 0.4303, 0.4341],\n",
      "          [0.4235, 0.4334, 0.4248,  ..., 0.4289, 0.4252, 0.4319],\n",
      "          ...,\n",
      "          [0.4367, 0.4220, 0.4287,  ..., 0.4213, 0.4206, 0.4243],\n",
      "          [0.4286, 0.4254, 0.4193,  ..., 0.4286, 0.4203, 0.4259],\n",
      "          [0.4304, 0.4259, 0.4316,  ..., 0.4340, 0.4253, 0.4266]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:03,  3.81s/it]\u001b[A\n",
      "2it [00:06,  3.35s/it]\u001b[A\n",
      "3it [00:10,  3.29s/it]\u001b[A\n",
      "4it [00:13,  3.25s/it]\u001b[A\n",
      "5it [00:16,  3.18s/it]\u001b[A\n",
      "6it [00:19,  3.13s/it]\u001b[A\n",
      "7it [00:22,  3.21s/it]\u001b[A\n",
      "8it [00:25,  3.14s/it]\u001b[A\n",
      "9it [00:29,  3.22s/it]\u001b[A\n",
      "10it [00:32,  3.17s/it]\u001b[A\n",
      "11it [00:36,  3.66s/it]\u001b[A\n",
      "12it [00:40,  3.72s/it]\u001b[A\n",
      "13it [00:45,  3.90s/it]\u001b[A\n",
      "14it [00:49,  3.92s/it]\u001b[A\n",
      "15it [00:52,  3.86s/it]\u001b[A\n",
      "16it [00:56,  3.85s/it]\u001b[A\n",
      "17it [01:00,  3.75s/it]\u001b[A\n",
      "18it [01:03,  3.69s/it]\u001b[A\n",
      "19it [01:07,  3.72s/it]\u001b[A\n",
      "20it [01:11,  3.73s/it]\u001b[A\n",
      "21it [01:14,  3.64s/it]\u001b[A\n",
      "22it [01:18,  3.61s/it]\u001b[A\n",
      "23it [01:22,  3.69s/it]\u001b[A\n",
      "24it [01:25,  3.56s/it]\u001b[A\n",
      "25it [01:28,  3.49s/it]\u001b[A\n",
      "26it [01:31,  3.42s/it]\u001b[A\n",
      "27it [01:34,  3.31s/it]\u001b[A\n",
      "28it [01:38,  3.33s/it]\u001b[A\n",
      "29it [01:41,  3.30s/it]\u001b[A\n",
      "30it [01:44,  3.22s/it]\u001b[A\n",
      "31it [01:48,  3.44s/it]\u001b[A\n",
      "32it [01:52,  3.65s/it]\u001b[A\n",
      "33it [01:55,  3.50s/it]\u001b[A\n",
      "34it [01:58,  3.38s/it]\u001b[A\n",
      "35it [02:02,  3.31s/it]\u001b[A\n",
      "36it [02:05,  3.25s/it]\u001b[A\n",
      "37it [02:08,  3.21s/it]\u001b[A\n",
      "38it [02:11,  3.23s/it]\u001b[A\n",
      "39it [02:14,  3.20s/it]\u001b[A\n",
      "40it [02:18,  3.25s/it]\u001b[A\n",
      "41it [02:21,  3.28s/it]\u001b[A\n",
      "42it [02:24,  3.32s/it]\u001b[A\n",
      "43it [02:27,  3.26s/it]\u001b[A\n",
      "44it [02:31,  3.23s/it]\u001b[A\n",
      "45it [02:34,  3.23s/it]\u001b[A\n",
      "46it [02:37,  3.16s/it]\u001b[A\n",
      "47it [02:40,  3.24s/it]\u001b[A\n",
      "48it [02:43,  3.22s/it]\u001b[A\n",
      "49it [02:47,  3.19s/it]\u001b[A\n",
      "50it [02:50,  3.22s/it]\u001b[A\n",
      "51it [02:53,  3.19s/it]\u001b[A\n",
      "52it [02:56,  3.24s/it]\u001b[A\n",
      "53it [02:59,  3.20s/it]\u001b[A\n",
      "54it [03:03,  3.19s/it]\u001b[A\n",
      "55it [03:06,  3.36s/it]\u001b[A\n",
      "56it [03:10,  3.49s/it]\u001b[A\n",
      "57it [03:13,  3.36s/it]\u001b[A\n",
      "58it [03:16,  3.28s/it]\u001b[A\n",
      "59it [03:20,  3.40s/it]\u001b[A\n",
      "60it [03:24,  3.72s/it]\u001b[A\n",
      "61it [03:28,  3.56s/it]\u001b[A\n",
      "62it [03:31,  3.40s/it]\u001b[A\n",
      "63it [03:34,  3.35s/it]\u001b[A\n",
      "64it [03:37,  3.29s/it]\u001b[A\n",
      "65it [03:40,  3.22s/it]\u001b[A\n",
      "66it [03:43,  3.17s/it]\u001b[A\n",
      "67it [03:46,  3.19s/it]\u001b[A\n",
      "68it [03:50,  3.30s/it]\u001b[A\n",
      "69it [03:54,  3.58s/it]\u001b[A\n",
      "70it [03:58,  3.60s/it]\u001b[A\n",
      "71it [04:01,  3.44s/it]\u001b[A\n",
      "72it [04:05,  3.50s/it]\u001b[A\n",
      "73it [04:08,  3.58s/it]\u001b[A\n",
      "74it [04:12,  3.47s/it]\u001b[A\n",
      "75it [04:15,  3.36s/it]\u001b[A\n",
      "76it [04:18,  3.36s/it]\u001b[A\n",
      "77it [04:21,  3.32s/it]\u001b[A\n",
      "78it [04:25,  3.31s/it]\u001b[A\n",
      "79it [04:28,  3.27s/it]\u001b[A\n",
      "80it [04:31,  3.21s/it]\u001b[A\n",
      "81it [04:34,  3.22s/it]\u001b[A\n",
      "82it [04:37,  3.23s/it]\u001b[A\n",
      "83it [04:40,  3.15s/it]\u001b[A\n",
      "84it [04:43,  3.12s/it]\u001b[A\n",
      "85it [04:47,  3.16s/it]\u001b[A\n",
      "86it [04:50,  3.23s/it]\u001b[A\n",
      "87it [04:53,  3.23s/it]\u001b[A\n",
      "88it [04:57,  3.42s/it]\u001b[A\n",
      "89it [05:01,  3.64s/it]\u001b[A\n",
      "90it [05:06,  3.86s/it]\u001b[A\n",
      "91it [05:09,  3.86s/it]\u001b[A\n",
      "92it [05:14,  4.15s/it]\u001b[A\n",
      "93it [05:18,  4.13s/it]\u001b[A\n",
      "94it [05:22,  3.93s/it]\u001b[A\n",
      "95it [05:26,  3.89s/it]\u001b[A\n",
      "96it [05:29,  3.84s/it]\u001b[A\n",
      "97it [05:33,  3.87s/it]\u001b[A\n",
      "98it [05:37,  3.97s/it]\u001b[A\n",
      "99it [05:40,  3.44s/it]\u001b[A\n",
      "  7%|██▋                                      | 2/30 [11:18<2:38:24, 339.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "tensor([[[[0.4422, 0.4425, 0.4424,  ..., 0.4430, 0.4420, 0.4431],\n",
      "          [0.4423, 0.4418, 0.4428,  ..., 0.4422, 0.4428, 0.4424],\n",
      "          [0.4426, 0.4440, 0.4428,  ..., 0.4435, 0.4434, 0.4437],\n",
      "          ...,\n",
      "          [0.4412, 0.4420, 0.4437,  ..., 0.4443, 0.4441, 0.4439],\n",
      "          [0.4418, 0.4436, 0.4435,  ..., 0.4441, 0.4444, 0.4450],\n",
      "          [0.4417, 0.4421, 0.4428,  ..., 0.4455, 0.4449, 0.4443]],\n",
      "\n",
      "         [[0.4266, 0.4262, 0.4263,  ..., 0.4254, 0.4260, 0.4262],\n",
      "          [0.4265, 0.4274, 0.4258,  ..., 0.4266, 0.4264, 0.4265],\n",
      "          [0.4264, 0.4267, 0.4271,  ..., 0.4273, 0.4271, 0.4270],\n",
      "          ...,\n",
      "          [0.4270, 0.4280, 0.4266,  ..., 0.4272, 0.4265, 0.4271],\n",
      "          [0.4265, 0.4270, 0.4273,  ..., 0.4273, 0.4270, 0.4270],\n",
      "          [0.4262, 0.4261, 0.4271,  ..., 0.4265, 0.4275, 0.4276]],\n",
      "\n",
      "         [[0.4040, 0.4047, 0.4040,  ..., 0.4050, 0.4037, 0.4036],\n",
      "          [0.4043, 0.4051, 0.4054,  ..., 0.4045, 0.4048, 0.4046],\n",
      "          [0.4043, 0.4047, 0.4050,  ..., 0.4050, 0.4048, 0.4054],\n",
      "          ...,\n",
      "          [0.4048, 0.4058, 0.4051,  ..., 0.4050, 0.4034, 0.4058],\n",
      "          [0.4036, 0.4041, 0.4049,  ..., 0.4038, 0.4053, 0.4047],\n",
      "          [0.4046, 0.4046, 0.4046,  ..., 0.4048, 0.4052, 0.4052]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:04,  4.03s/it]\u001b[A\n",
      "2it [00:08,  4.45s/it]\u001b[A\n",
      "3it [00:12,  4.16s/it]\u001b[A\n",
      "4it [00:16,  3.90s/it]\u001b[A\n",
      "5it [00:19,  3.84s/it]\u001b[A\n",
      "6it [00:23,  3.72s/it]\u001b[A\n",
      "7it [00:26,  3.53s/it]\u001b[A\n",
      "8it [00:29,  3.44s/it]\u001b[A\n",
      "9it [00:33,  3.54s/it]\u001b[A\n",
      "10it [00:38,  3.95s/it]\u001b[A\n",
      "11it [00:41,  3.79s/it]\u001b[A\n",
      "12it [00:45,  3.67s/it]\u001b[A\n",
      "13it [00:49,  3.96s/it]\u001b[A\n",
      "14it [00:54,  4.34s/it]\u001b[A\n",
      "15it [00:58,  4.23s/it]\u001b[A\n",
      "16it [01:02,  4.07s/it]\u001b[A\n",
      "17it [01:06,  3.88s/it]\u001b[A\n",
      "18it [01:09,  3.63s/it]\u001b[A\n",
      "19it [01:12,  3.50s/it]\u001b[A\n",
      "20it [01:15,  3.39s/it]\u001b[A\n",
      "21it [01:18,  3.32s/it]\u001b[A\n",
      "22it [01:22,  3.35s/it]\u001b[A\n",
      "23it [01:25,  3.34s/it]\u001b[A\n",
      "24it [01:28,  3.25s/it]\u001b[A\n",
      "25it [01:31,  3.25s/it]\u001b[A\n",
      "26it [01:34,  3.26s/it]\u001b[A\n",
      "27it [01:38,  3.23s/it]\u001b[A\n",
      "28it [01:41,  3.20s/it]\u001b[A\n",
      "29it [01:44,  3.16s/it]\u001b[A\n",
      "30it [01:47,  3.18s/it]\u001b[A\n",
      "31it [01:50,  3.24s/it]\u001b[A\n",
      "32it [01:54,  3.21s/it]\u001b[A\n",
      "33it [01:57,  3.21s/it]\u001b[A\n",
      "34it [02:00,  3.20s/it]\u001b[A\n",
      "35it [02:03,  3.24s/it]\u001b[A\n",
      "36it [02:07,  3.28s/it]\u001b[A\n",
      "37it [02:11,  3.66s/it]\u001b[A\n",
      "38it [02:14,  3.51s/it]\u001b[A\n",
      "39it [02:17,  3.35s/it]\u001b[A\n",
      "40it [02:21,  3.36s/it]\u001b[A\n",
      "41it [02:24,  3.27s/it]\u001b[A\n",
      "42it [02:27,  3.25s/it]\u001b[A\n",
      "43it [02:30,  3.28s/it]\u001b[A\n",
      "44it [02:34,  3.26s/it]\u001b[A\n",
      "45it [02:37,  3.33s/it]\u001b[A\n",
      "46it [02:41,  3.37s/it]\u001b[A\n",
      "47it [02:44,  3.43s/it]\u001b[A\n",
      "48it [02:47,  3.42s/it]\u001b[A\n",
      "49it [02:50,  3.29s/it]\u001b[A\n",
      "50it [02:54,  3.25s/it]\u001b[A\n",
      "51it [02:57,  3.20s/it]\u001b[A\n",
      "52it [03:00,  3.19s/it]\u001b[A\n",
      "53it [03:03,  3.21s/it]\u001b[A\n",
      "54it [03:06,  3.21s/it]\u001b[A\n",
      "55it [03:09,  3.17s/it]\u001b[A\n",
      "56it [03:13,  3.24s/it]\u001b[A\n",
      "57it [03:16,  3.23s/it]\u001b[A\n",
      "58it [03:19,  3.20s/it]\u001b[A\n",
      "59it [03:22,  3.16s/it]\u001b[A\n",
      "60it [03:25,  3.12s/it]\u001b[A\n",
      "61it [03:29,  3.18s/it]\u001b[A\n",
      "62it [03:32,  3.21s/it]\u001b[A\n",
      "63it [03:35,  3.21s/it]\u001b[A\n",
      "64it [03:38,  3.21s/it]\u001b[A\n",
      "65it [03:42,  3.27s/it]\u001b[A\n",
      "66it [03:45,  3.29s/it]\u001b[A\n",
      "67it [03:48,  3.33s/it]\u001b[A\n",
      "68it [03:52,  3.27s/it]\u001b[A\n",
      "69it [03:55,  3.26s/it]\u001b[A\n",
      "70it [03:58,  3.28s/it]\u001b[A\n",
      "71it [04:01,  3.29s/it]\u001b[A\n",
      "72it [04:05,  3.34s/it]\u001b[A\n",
      "73it [04:09,  3.47s/it]\u001b[A\n",
      "74it [04:13,  3.81s/it]\u001b[A\n",
      "75it [04:17,  3.85s/it]\u001b[A\n",
      "76it [04:21,  3.76s/it]\u001b[A\n",
      "77it [04:24,  3.74s/it]\u001b[A\n",
      "78it [04:28,  3.72s/it]\u001b[A\n",
      "79it [04:31,  3.57s/it]\u001b[A\n",
      "80it [04:35,  3.48s/it]\u001b[A\n",
      "81it [04:38,  3.38s/it]\u001b[A\n",
      "82it [04:41,  3.32s/it]\u001b[A\n",
      "83it [04:44,  3.30s/it]\u001b[A\n",
      "84it [04:47,  3.25s/it]\u001b[A\n",
      "85it [04:50,  3.17s/it]\u001b[A\n",
      "86it [04:53,  3.13s/it]\u001b[A\n",
      "87it [04:57,  3.20s/it]\u001b[A\n",
      "88it [05:01,  3.59s/it]\u001b[A\n",
      "89it [05:05,  3.67s/it]\u001b[A\n",
      "90it [05:09,  3.78s/it]\u001b[A\n",
      "91it [05:13,  3.89s/it]\u001b[A\n",
      "92it [05:17,  3.96s/it]\u001b[A\n",
      "93it [05:21,  3.95s/it]\u001b[A\n",
      "94it [05:25,  4.00s/it]\u001b[A\n",
      "95it [05:29,  3.97s/it]\u001b[A\n",
      "96it [05:33,  3.93s/it]\u001b[A\n",
      "97it [05:37,  4.01s/it]\u001b[A\n",
      "98it [05:41,  4.02s/it]\u001b[A\n",
      "99it [05:44,  3.48s/it]\u001b[A\n",
      " 10%|████                                     | 3/30 [17:03<2:33:48, 341.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2\n",
      "tensor([[[[0.4189, 0.4198, 0.4201,  ..., 0.4188, 0.4182, 0.4184],\n",
      "          [0.4186, 0.4188, 0.4201,  ..., 0.4194, 0.4184, 0.4196],\n",
      "          [0.4182, 0.4175, 0.4180,  ..., 0.4196, 0.4189, 0.4193],\n",
      "          ...,\n",
      "          [0.4186, 0.4161, 0.4192,  ..., 0.4215, 0.4217, 0.4221],\n",
      "          [0.4185, 0.4151, 0.4145,  ..., 0.4207, 0.4212, 0.4208],\n",
      "          [0.4185, 0.4170, 0.4188,  ..., 0.4214, 0.4202, 0.4208]],\n",
      "\n",
      "         [[0.4121, 0.4126, 0.4125,  ..., 0.4121, 0.4118, 0.4120],\n",
      "          [0.4120, 0.4138, 0.4128,  ..., 0.4134, 0.4118, 0.4133],\n",
      "          [0.4119, 0.4119, 0.4111,  ..., 0.4125, 0.4122, 0.4125],\n",
      "          ...,\n",
      "          [0.4119, 0.4147, 0.4131,  ..., 0.4133, 0.4135, 0.4139],\n",
      "          [0.4119, 0.4111, 0.4084,  ..., 0.4133, 0.4129, 0.4133],\n",
      "          [0.4119, 0.4105, 0.4127,  ..., 0.4127, 0.4125, 0.4129]],\n",
      "\n",
      "         [[0.4026, 0.4028, 0.4032,  ..., 0.4029, 0.4018, 0.4026],\n",
      "          [0.4024, 0.4042, 0.4037,  ..., 0.4036, 0.4028, 0.4030],\n",
      "          [0.4020, 0.4018, 0.4028,  ..., 0.4032, 0.4026, 0.4025],\n",
      "          ...,\n",
      "          [0.4023, 0.4050, 0.4041,  ..., 0.4038, 0.4033, 0.4039],\n",
      "          [0.4021, 0.4005, 0.4011,  ..., 0.4031, 0.4039, 0.4032],\n",
      "          [0.4024, 0.4004, 0.4029,  ..., 0.4031, 0.4028, 0.4033]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:05,  5.51s/it]\u001b[A\n",
      "2it [00:10,  5.15s/it]\u001b[A\n",
      "3it [00:14,  4.72s/it]\u001b[A\n",
      "4it [00:19,  4.60s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 30\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(epochs)):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in tqdm(enumerate(train_loader)):\n",
    "        b+=1\n",
    "        X_train = X_train.view(-1,1,128,128)\n",
    "        y_train = y_train.view(-1,3,128,128)\n",
    "        \n",
    "        X_train = X_train/255\n",
    "        y_train = y_train/255\n",
    "\n",
    "        \n",
    "        # Apply the model\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    " \n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    train_losses.append(loss)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        actual = (y_train[20]).reshape(1,3,128,128)\n",
    "    \n",
    "        c = model((X_train[20]).reshape(1,1,128,128))\n",
    "    print(f\"Epoch : {i}\")\n",
    "    #print(c)\n",
    "    plot_image(c,i,actual)\n",
    "    \n",
    "   \n",
    "        \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22dc9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for b, (X_test, y_test) in enumerate(val_loader):\n",
    "        X_test = X_test.view(-1,1,128,128)\n",
    "        y_out = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab63dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    c = model((X_train[12]).reshape(1,1,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36b1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[20].reshape(128,128,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc34e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(c.reshape(128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    " for b, (X_train, y_train) in tqdm(enumerate(train_loader)):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_train[20].reshape(128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff977e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[20]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b755c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('graph.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
